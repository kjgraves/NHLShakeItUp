{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape NHL Additional Data\n",
    "In this notebook, I show how I get the rest of the data as input into my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start from the dataframe that I built when scraping the lines for each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/Lineups16_17.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping from https://www.hockey-reference.com\n",
    "**List of data to get from each game**:\n",
    "\n",
    "(Only those marked with * have been implemented so far)\n",
    "\n",
    "Team Data: \n",
    "* Date *     \n",
    "* Score *    \n",
    "* Shots     \n",
    "* OT of SO win *\n",
    "* Points    \n",
    "* Corsi for events \n",
    "\n",
    "Player Data:\n",
    "* +/- *\n",
    "* Corsi for events \n",
    "* Corsi against events \n",
    "* Goals *\n",
    "* PP Goals *\n",
    "* Assists *\n",
    "* Penalty Minutes *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.hockey-reference.com/leagues/NHL_2017_games.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season_tag = soup.find('table',{\"id\":'games'})\n",
    "ind_game_tags = reg_season_tag.find('tbody').find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngames = len(ind_game_tags)\n",
    "dates     = pd.Series([np.datetime64('2009-01-01')]*Ngames)\n",
    "AwayTeams = np.empty(Ngames,dtype='U3')\n",
    "HomeTeams = np.empty(Ngames,dtype='U3')\n",
    "AwayScore = np.zeros(Ngames,dtype=int)\n",
    "HomeScore = np.zeros(Ngames,dtype=int)\n",
    "lOTwin    = np.empty(Ngames,dtype='?')\n",
    "lSOwin    = np.empty(Ngames,dtype='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Ngames):\n",
    "    dates[i]     = ind_game_tags[i].find('th',{'data-stat':'date_game'}).find('a').text\n",
    "    AwayTeams[i] = ind_game_tags[i].find('td',{'data-stat':'visitor_team_name'}).attrs['csk'][:3]\n",
    "    HomeTeams[i] = ind_game_tags[i].find('td',{'data-stat':'home_team_name'}).attrs['csk'][:3]\n",
    "    AwayScore[i] = ind_game_tags[i].find('td',{'data-stat':'visitor_goals'}).text\n",
    "    HomeScore[i] = ind_game_tags[i].find('td',{'data-stat':'home_goals'}).text\n",
    "    lOTwin[i]    = ind_game_tags[i].find('td',{'data-stat':'overtimes'}).text == 'OT'\n",
    "    lSOwin[i]    = ind_game_tags[i].find('td',{'data-stat':'overtimes'}).text == 'SO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add 'em to the data frame, but first I will check if the dates and teams match up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.all(( (dates == df['Date']).all(),\n",
    "               (AwayTeams == df['Away Team']).all(),\n",
    "               (HomeTeams == df['Home Team']).all() )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Away Score'] = AwayScore\n",
    "df['Home Score'] = HomeScore\n",
    "df['OT Win'] = lOTwin\n",
    "df['SO Win'] = lSOwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "new_cols = cols[:4] + cols[-4:] + cols[4:-4]\n",
    "df = df[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Away Score</th>\n",
       "      <th>Home Score</th>\n",
       "      <th>OT Win</th>\n",
       "      <th>SO Win</th>\n",
       "      <th>AL1-0</th>\n",
       "      <th>AL1-1</th>\n",
       "      <th>...</th>\n",
       "      <th>HL1-2</th>\n",
       "      <th>HL2-0</th>\n",
       "      <th>HL2-1</th>\n",
       "      <th>HL2-2</th>\n",
       "      <th>HL3-0</th>\n",
       "      <th>HL3-1</th>\n",
       "      <th>HL3-2</th>\n",
       "      <th>HL4-0</th>\n",
       "      <th>HL4-1</th>\n",
       "      <th>HL4-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>16_17</td>\n",
       "      <td>STL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Paul Stastny</td>\n",
       "      <td>Alexander Steen</td>\n",
       "      <td>...</td>\n",
       "      <td>Jonathan Toews</td>\n",
       "      <td>Artemi Panarin</td>\n",
       "      <td>Patrick Kane</td>\n",
       "      <td>Artem Anisimov</td>\n",
       "      <td>Tyler Motte</td>\n",
       "      <td>Marcus Kruger</td>\n",
       "      <td>Ryan Hartman</td>\n",
       "      <td>Jordin Tootoo</td>\n",
       "      <td>Vincent Hinostroza</td>\n",
       "      <td>Nick Schmaltz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>16_17</td>\n",
       "      <td>CGY</td>\n",
       "      <td>EDM</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Kris Versteeg</td>\n",
       "      <td>Johnny Gaudreau</td>\n",
       "      <td>...</td>\n",
       "      <td>Milan Lucic</td>\n",
       "      <td>Anton Slepyshev</td>\n",
       "      <td>Benoit Pouliot</td>\n",
       "      <td>Ryan Nugent-Hopkins</td>\n",
       "      <td>Patrick Maroon</td>\n",
       "      <td>Leon Draisaitl</td>\n",
       "      <td>Jesse Puljujarvi</td>\n",
       "      <td>Tyler Pitlick</td>\n",
       "      <td>Mark Letestu</td>\n",
       "      <td>Zack Kassian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>16_17</td>\n",
       "      <td>TOR</td>\n",
       "      <td>OTT</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Milan Michalek</td>\n",
       "      <td>Leo Komarov</td>\n",
       "      <td>...</td>\n",
       "      <td>Mark Stone</td>\n",
       "      <td>Zack Smith</td>\n",
       "      <td>Bobby Ryan</td>\n",
       "      <td>Derick Brassard</td>\n",
       "      <td>Tom Pyatt</td>\n",
       "      <td>Jean-Gabriel Pageau</td>\n",
       "      <td>Philip Varone</td>\n",
       "      <td>Ryan Dzingel</td>\n",
       "      <td>Chris Neil</td>\n",
       "      <td>Chris Kelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>16_17</td>\n",
       "      <td>LAK</td>\n",
       "      <td>SJS</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Anze Kopitar</td>\n",
       "      <td>Dustin Brown</td>\n",
       "      <td>...</td>\n",
       "      <td>Tomas Hertl</td>\n",
       "      <td>Logan Couture</td>\n",
       "      <td>Mikkel Boedker</td>\n",
       "      <td>Joonas Donskoi</td>\n",
       "      <td>Joel Ward</td>\n",
       "      <td>Chris Tierney</td>\n",
       "      <td>Patrick Marleau</td>\n",
       "      <td>Tommy Wingels</td>\n",
       "      <td>Matt Nieto</td>\n",
       "      <td>Melker Karlsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>16_17</td>\n",
       "      <td>MTL</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Alex Galchenyuk</td>\n",
       "      <td>Brendan Gallagher</td>\n",
       "      <td>...</td>\n",
       "      <td>Evander Kane</td>\n",
       "      <td>Marcus Foligno</td>\n",
       "      <td>Johan Larsson</td>\n",
       "      <td>Tyler Ennis</td>\n",
       "      <td>Zemgus Girgensons</td>\n",
       "      <td>Hudson Fasching</td>\n",
       "      <td>Matt Moulson</td>\n",
       "      <td>Nicolas Deslauriers</td>\n",
       "      <td>Brian Gionta</td>\n",
       "      <td>Derek Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Season Away Team Home Team  Away Score  Home Score  OT Win  \\\n",
       "0 2016-10-12  16_17       STL       CHI           5           2   False   \n",
       "1 2016-10-12  16_17       CGY       EDM           4           7   False   \n",
       "2 2016-10-12  16_17       TOR       OTT           4           5    True   \n",
       "3 2016-10-12  16_17       LAK       SJS           1           2   False   \n",
       "4 2016-10-13  16_17       MTL       BUF           4           1   False   \n",
       "\n",
       "   SO Win            AL1-0              AL1-1       ...         \\\n",
       "0   False     Paul Stastny    Alexander Steen       ...          \n",
       "1   False    Kris Versteeg    Johnny Gaudreau       ...          \n",
       "2   False   Milan Michalek        Leo Komarov       ...          \n",
       "3   False     Anze Kopitar       Dustin Brown       ...          \n",
       "4   False  Alex Galchenyuk  Brendan Gallagher       ...          \n",
       "\n",
       "            HL1-2            HL2-0           HL2-1                HL2-2  \\\n",
       "0  Jonathan Toews   Artemi Panarin    Patrick Kane       Artem Anisimov   \n",
       "1     Milan Lucic  Anton Slepyshev  Benoit Pouliot  Ryan Nugent-Hopkins   \n",
       "2      Mark Stone       Zack Smith      Bobby Ryan      Derick Brassard   \n",
       "3     Tomas Hertl    Logan Couture  Mikkel Boedker       Joonas Donskoi   \n",
       "4    Evander Kane   Marcus Foligno   Johan Larsson          Tyler Ennis   \n",
       "\n",
       "               HL3-0                HL3-1             HL3-2  \\\n",
       "0        Tyler Motte        Marcus Kruger      Ryan Hartman   \n",
       "1     Patrick Maroon       Leon Draisaitl  Jesse Puljujarvi   \n",
       "2          Tom Pyatt  Jean-Gabriel Pageau     Philip Varone   \n",
       "3          Joel Ward        Chris Tierney   Patrick Marleau   \n",
       "4  Zemgus Girgensons      Hudson Fasching      Matt Moulson   \n",
       "\n",
       "                 HL4-0               HL4-1            HL4-2  \n",
       "0        Jordin Tootoo  Vincent Hinostroza    Nick Schmaltz  \n",
       "1        Tyler Pitlick        Mark Letestu     Zack Kassian  \n",
       "2         Ryan Dzingel          Chris Neil      Chris Kelly  \n",
       "3        Tommy Wingels          Matt Nieto  Melker Karlsson  \n",
       "4  Nicolas Deslauriers        Brian Gionta      Derek Grant  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I grab all of the data, I need to build the appropriate columns in the dataframe.\n",
    "\n",
    "Columns to add:\n",
    "* Number of Goals, by position (e.g. ``Goals AL1-0``, ``Goals HL2-1``, etc.).\n",
    "* Number of PP Goals, by position.\n",
    "* Number of Assists, by position.\n",
    "* Number of PP Assists, by position.\n",
    "* Number of Shots, by position.\n",
    "* +/- for each position.\n",
    "* Penalty minutes by position.\n",
    "* Lineup Error, by lines (i.e. fantasy sites may have errors for lineups, & for now I will just mark the lines with errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in (\"A\",\"H\"):\n",
    "    for line in range(1,5):\n",
    "        for pos in range(3):\n",
    "            df['Goals {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "            df['PP Goals {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "            df['Assists {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "            df['PP Assists {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "            df['Shots {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "            df['+/- {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "            df['PM {0}L{1}-{2}'.format(loc,line,pos)] = 0\n",
    "        df['Lineup Error {0}L{1}'.format(loc,line)] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scraping\n",
    "Now, let's scrape data from https://www.hockey-reference.com for each individual game. The syntax for each game in the url looks to be ``https://www.hockey-reference.com/boxscores/YYYYMMDDNTeamAbbrev.html``. Where ``YYYYMMDD`` is the date in that form, ``N`` seems to always be 0 (maybe it has to do with the number of games by the home team that day?), and ``TeamName`` is the name of the home team.\n",
    "\n",
    "First, I write a function ``add_stats`` to add all of the stats to a particular position, given a tag of the appropriate player's row (mostly to make things easier to read). Then, I have to account for some names that are not the same between different sites (e.g. Alex Steen vs. Alexander Steen). I do this with a ``check_name`` function Finally, I run the big loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stats(skater,df,i,loc,line,pos):\n",
    "    \"\"\"\n",
    "    Add the stats of:\n",
    "    Goals, PP Goals, Assists, PP Assists, Shots, +/-, and Penaty Minutes\n",
    "    to the dataframe using the html tag containing the row on hockey-reference.com \n",
    "    with the appropriate data.\n",
    "    INPUT:\n",
    "        skater: html tag of row in table with all of the players stats\n",
    "        df: Dataframe to add data to\n",
    "        i: index/row of dataframe to use\n",
    "        loc: Team location (Home or Away)\n",
    "        line: Line number [1-4]\n",
    "        pos: index/position on line [0-2]\n",
    "    OUTPUT:\n",
    "        None (Just alters dataframe)\n",
    "    \"\"\"\n",
    "    df['Goals {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'goals'}).text\n",
    "    df['PP Goals {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'goals_pp'}).text\n",
    "    df['Assists {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'assists'}).text\n",
    "    df['PP Assists {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'assists_pp'}).text\n",
    "    df['Shots {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'shots'}).text\n",
    "    df['+/- {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'plus_minus'}).text\n",
    "    df['PM {0}L{1}-{2}'.format(loc,line,pos)].iat[i] = \\\n",
    "        skater.find('td',{'data-stat':'pen_min'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(name1,name2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    retval = False\n",
    "    #print(\"|{0}|{1}|\".format(name1,name2))\n",
    "    if name1.lower() == name2.lower():\n",
    "        retval = True\n",
    "    else:\n",
    "        n1 = name1.split()\n",
    "        n2 = name2.split()\n",
    "        # Alex = Alexander\n",
    "        if (n1[1] == n2[1] and \n",
    "            ((n1[0] == 'Alex' and n2[0] == 'Alexander') or\n",
    "            (n1[0] == 'Alexander' and n2[0] == 'Alex'))):\n",
    "            retval = True\n",
    "        # I think someone mixed up Micheal (Micheal Ferland) for Michael\n",
    "        if ((not retval) and (n1[1] == n2[1]) and\n",
    "            ((n1[0] == 'Michael' and n2[0] == 'Micheal') or\n",
    "            (n1[0] == 'Micheal' and n2[0] == 'Michael'))):\n",
    "            retval = True\n",
    "        # Mitch = Mitchell\n",
    "        if ((not retval) and (n1[1] == n2[1]) and\n",
    "            ((n1[0] == 'Mitch' and n2[0] == 'Mitchell') or\n",
    "            (n1[0] == 'Mitchell' and n2[0] == 'Mitch'))):\n",
    "            retval = True\n",
    "        # Phil = Philip = Phillip\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Phil' and n2[0] == 'Philip') or\n",
    "            (n1[0] == 'Philip' and n2[0] == 'Phil')  or\n",
    "            (n1[0] == 'Phillip' and n2[0] == 'Phil') or\n",
    "            (n1[0] == 'Phil' and n2[0] == 'Phillip'))):\n",
    "            retval = True\n",
    "        # Pierre-Alexandre Parenteau = P.A. Parenteau\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Pierre-Alexandre' and n2[0] == 'P.A.') or\n",
    "            (n1[0] == 'P.A.' and n2[0] == 'Pierre-Alexandre'))):\n",
    "            retval = True\n",
    "        # Jon = Jonathan\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Jon' and n2[0] == 'Jonathan') or\n",
    "            (n1[0] == 'Jonathan' and n2[0] == 'Jon'))):\n",
    "            retval = True\n",
    "        # Zach = Zachary\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Zach' and n2[0] == 'Zachary') or\n",
    "            (n1[0] == 'Zachary' and n2[0] == 'Zach'))):\n",
    "            retval = True\n",
    "        # Vinnie = Vincent\n",
    "        if ((not retval) and (n1[1] == n2[1]) and\n",
    "            ((n1[0] == 'Vinnie' and n2[0] == 'Vincent') or\n",
    "             (n1[0] == 'Vincent' and n2[0] == 'Vinnie'))):\n",
    "            retval = True\n",
    "        # Joel Eriksson Ek = Joel Eriksson-Ek\n",
    "        if ((not retval) and\n",
    "            ((name1 == 'Joel Eriksson Ek' and name2 == 'Joel Eriksson-Ek') or\n",
    "             (name1 == 'Joel Eriksson-Ek' and name2 == 'Joel Eriksson Ek') )):\n",
    "            retval = True\n",
    "        # Chris = Christopher\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Chris' and n2[0] == 'Christopher') or\n",
    "             (n1[0] == 'Christopher' and n2[0] == 'Chris'))):\n",
    "            retval = True\n",
    "        # Matt = Matthew\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Matt' and n2[0] == 'Matthew') or\n",
    "             (n1[0] == 'Matthew' and n2[0] == 'Matt'))):\n",
    "            retval = True\n",
    "        # Jt = J.T. \n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'J.T.' and n2[0] == 'Jt') or\n",
    "             (n1[0] == 'Jt' and n2[0] == 'J.T.'))):\n",
    "            retval = True\n",
    "        # Tj = T.J. \n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Tj' and n2[0] == 'T.J.') or\n",
    "             (n1[0] == 'T.J.' and n2[0] == 'Tj'))):\n",
    "            retval = True\n",
    "        # Aj = A.J.\n",
    "        if ((not retval) and (n1[1] == n2[1]) and \n",
    "            ((n1[0] == 'Aj' and n2[0] == 'A.J.') or\n",
    "             (n1[0] == 'A.J.' and n2[0] == 'Aj'))):\n",
    "            retval = True\n",
    "        #if ( (not retval) and (n2[1] == n1[1])):\n",
    "            #print(\"Last Name Same:{0}|{1}\".format(name1,name2))\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    date = df['Date'].iat[i]\n",
    "    date = date.strftime('%Y%m%d')\n",
    "    HomeTeam = df['Home Team'].iat[i]\n",
    "    #print(\"date = {0}\".format(date))\n",
    "    #print(\"Home Team = {0}\".format(HomeTeam))\n",
    "    try:\n",
    "        soup = BeautifulSoup(open(\"data/hockey-ref-boxscore{0}{1}{2}.html\".format(date,0,HomeTeam)), \"html.parser\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"https://www.hockey-reference.com/boxscores/{0}{1}{2}.html\".format(date,0,HomeTeam))\n",
    "        page = requests.get(\"https://www.hockey-reference.com/boxscores/{0}{1}{2}.html\".format(date,0,HomeTeam))\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        with open(\"data/hockey-ref-boxscore{0}{1}{2}.html\".format(date,0,HomeTeam), \"w\") as f:\n",
    "            f.write(str(soup))\n",
    "    for loc in (\"A\",\"H\"):\n",
    "        Num_not_found = 0\n",
    "        lines_not_found = []\n",
    "        if loc == \"A\":\n",
    "            team = df['Away Team'].iat[i]\n",
    "        else:\n",
    "            team = HomeTeam\n",
    "        table_tag = soup.find('table',{'id':\"{0}_skaters\".format(team)}).find('tbody')\n",
    "        all_skaters = table_tag.find_all('tr')\n",
    "        # Loop through positions on dataframe (to ensure all are found)\n",
    "        for line in range(1,5):\n",
    "            for pos in range(3):\n",
    "                lfound = False\n",
    "                for skater in all_skaters:\n",
    "                    # Ignore any line positions without a player (but don't make that game an error)\n",
    "                    if df['{0}L{1}-{2}'.format(loc,line,pos)].iat[i] == \"None None\":\n",
    "                        lfound = True\n",
    "                        break\n",
    "                    if check_name(skater.find('td',{'data-stat':'player'}).find('a').text,\n",
    "                                  df['{0}L{1}-{2}'.format(loc,line,pos)].iat[i]):      \n",
    "                        add_stats(skater,df,i,loc,line,pos)\n",
    "                        lfound = True\n",
    "                        break\n",
    "                if not lfound:\n",
    "                    #print(\"Can't find {0} ({1}) in game data of {2} vs {3} on {4}\".format(\n",
    "                            #df['{0}L{1}-{2}'.format(loc,line,pos)].iat[i],loc,\n",
    "                            #df['Away Team'].iat[i],df['Home Team'].iat[i],df['Date'].iat[i]))\n",
    "                    # Set Lineup Error = True\n",
    "                    df['Lineup Error {0}L{1}'.format(loc,line)].iat[i] = True\n",
    "                    Num_not_found += 1\n",
    "                    lines_not_found.append('L{0}-{1}'.format(line,pos))\n",
    "                    #if Num_not_found > 1:\n",
    "                        #print(\"Number not found > 1 for {0} Team\".format(loc))\n",
    "                        #print(\"Lines with player mistakes = {0}\".format(','.join(lines_not_found)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Point!\n",
    "This looks like a good place for a save point! The data does have a number of mistakes in it (see below for discussion about the mistakes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Season', 'Away Team', 'Home Team', 'Away Score', 'Home Score',\n",
      "       'OT Win', 'SO Win', 'AL1-0', 'AL1-1',\n",
      "       ...\n",
      "       '+/- HL4-1', 'PM HL4-1', 'Goals HL4-2', 'PP Goals HL4-2',\n",
      "       'Assists HL4-2', 'PP Assists HL4-2', 'Shots HL4-2', '+/- HL4-2',\n",
      "       'PM HL4-2', 'Lineup Error HL4'],\n",
      "      dtype='object', length=208)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/FullData_Messy.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Some Messy Data \n",
    "### (In Progress)\n",
    "Apart from fixing some of the names, I have not tried to handle any lineup mistakes. These seem to result from the differences in the lineups in rotogrinders.com vs hockey-reference.com. It looks that rotogrinders seems to make more of the mistakes (e.g. listing players that did not play in the game). To fix this I will use the actual nhl.com/gamecenter data. I didn't use this before because it is very similar to hockey-reference.com and hockey-reference is a MUCH more simple site to scrape. For the nhl.com/stats site, I will have to use a different scraping tool (I am pretty sure there is javascript code used for generating the table that I need). However, the nhl.com/gamecenter data breaks down their table between defensemen and forwards. If there is only one missing/erroneous player per team in each game, we could replace him with the correct one (and assume that any other lines stayed the same).\n",
    "I may also check other fantasy sites, if I can find them.\n",
    "\n",
    "It turns out that I will also need to convert NHL team abbreviations into their names. Fun. So here is the dictionary to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab2name = {\"ANA\" : \"Anaheim Ducks\",\n",
    "    \"ARI\" : \"Arizona Coyotes\",\n",
    "    \"BOS\" : \"Boston Bruins\",\n",
    "    \"BUF\" : \"Buffalo Sabres\",\n",
    "    \"CAR\" : \"Carolina Hurricanes\",\n",
    "    \"CGY\" : \"Calgary Flames\",\n",
    "    \"CHI\" : \"Chicago Blackhawks\",\n",
    "    \"CBJ\" : \"Columbus Blue Jackets\",\n",
    "    \"COL\" : \"Colorado Avalanche\",\n",
    "    \"DAL\" : \"Dallas Stars\",\n",
    "    \"DET\" : \"Detroit Red Wings\",\n",
    "    \"EDM\" : \"Edmonton Oilers\",\n",
    "    \"FLA\" : \"Florida Panthers\",\n",
    "    \"LAK\" : \"Los Angeles Kings\",\n",
    "    \"MIN\" : \"Minnesota Wild\",\n",
    "    \"MTL\" : \"Montreal Canadiens\",\n",
    "    \"NSH\" : \"Nashville Predators\",\n",
    "    \"NJD\" : \"New Jersey Devils\",\n",
    "    \"NYI\" : \"New York Islanders\",\n",
    "    \"NYR\" : \"New York Rangers\",\n",
    "    \"OTT\" : \"Ottawa Senators\",\n",
    "    \"PHI\" : \"Philadelphia Flyers\",\n",
    "    \"PHX\" : \"Phoenix Coyotes\",\n",
    "    \"PIT\" : \"Pittsburgh Penguins\",\n",
    "    \"SJS\" : \"San Jose Sharks\",\n",
    "    \"STL\" : \"St. Louis Blues\",\n",
    "    \"TBL\" : \"Tampa Bay Lightning\",\n",
    "    \"TOR\" : \"Toronto Maple Leafs\",\n",
    "    \"VAN\" : \"Vancouver Canucks\",\n",
    "    \"VGK\" : \"Vegas Golden Knights\",\n",
    "    \"WPG\" : \"Winnipeg Jets\",\n",
    "    \"WSH\" : \"Washington Capitals\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also need to load in ``selenium`` to get the full html output of the nhl.com/stats page that I need. I will run a headless firefox driver. (Note: There is a bit of work to actually make this work, but I am not going to dive into explaining it now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(firefox_options=options) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can find all of the mistakes by the \"Lineup Error\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for loc in (\"A\",\"H\"):\n",
    "    for line in range(1,2):\n",
    "        if n == 0:\n",
    "            val = df[\"Lineup Error {0}L{1}\".format(loc,line)] \n",
    "        else:\n",
    "            val = val | df[\"Lineup Error {0}L{1}\".format(loc,line)]\n",
    "        n += 1\n",
    "print(len(np.where(val == True)[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url for the actual stats for each game has a somewhat arbitrary numbering system in it. It has to do with the number of the game in the season and the type of game (preseason, regular, and playoffs I believe). It would be very complicated to attempt to find it (and would be difficult with many games occuring on the same day. To avoid this, I will search for the game from the nhl.com/stats website (see url in code below), and pull the appropriate gamecenter url from that page.\n",
    "\n",
    "\n",
    "Then, after some more complicated scraping, I attempt to determine situations where I can actually know the lines, and I replace the player in the dataframe.\n",
    "\n",
    "\n",
    "Sorry, this is a beast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lineup Error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lineup Error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-587b8ea1f3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                           {2} = date in YYYY/MM/DD, {3} = gamecenter id number)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnhl_gc_base_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.nhl.com/gamecenter/{0}-vs-{1}/{2}/{3}#game={3},game_state=final,game_tab=stats\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mind_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Lineup Error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mnum_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnum_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lineup Error'"
     ]
    }
   ],
   "source": [
    "# Url to find the correct gamecenter url (0 = date in YYYY-MM-DD)\n",
    "nhl_base_url = \"http://www.nhl.com/stats/team?reportType=game&dateFrom={0}&dateTo={0}&gameType=2\"\n",
    "# Specific Gamecenter url ( {0} = lowercase away abbrev., {1} = lowercase home abbrev.,\n",
    "#                           {2} = date in YYYY/MM/DD, {3} = gamecenter id number)\n",
    "nhl_gc_base_url = \"https://www.nhl.com/gamecenter/{0}-vs-{1}/{2}/{3}#game={3},game_state=final,game_tab=stats\"   \n",
    "ind_err = np.where(df[\"Lineup Error\"] == True)[0]\n",
    "num_check = 0\n",
    "num_fix = 0\n",
    "for i in ind_err:\n",
    "    # get date and team names from the dataframe\n",
    "    date  = df['Date'].iat[i]\n",
    "    ATeam = df['Away Team'].iat[i]\n",
    "    HTeam = df['Home Team'].iat[i]\n",
    "    print(i,date,ATeam,HTeam)\n",
    "    # Scrape the nhl.com/stats site to find the gamecenter webpage\n",
    "    try:\n",
    "        soup = BeautifulSoup(open(\"data/nhl_stats_search{0}.html\".format(date)), \"html.parser\")\n",
    "    except FileNotFoundError:\n",
    "        print(nhl_base_url.format(date))\n",
    "        driver.get(nhl_base_url.format(date))\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        with open(\"data/nhl_stats_search{0}.html\".format(date), \"w\") as f:\n",
    "            f.write(str(soup))\n",
    "    rows = soup.find('div',{'class':\"rt-tbody\"}).find_all('div',{'class':\"rt-tr-group\"}) \n",
    "    for row in rows:\n",
    "        # The columns are only organized by index\n",
    "        entries = row.find_all('div',{'class':'rt-td'})\n",
    "        Team1Name   = entries[1].text\n",
    "        Team2Abbrev = entries[2].text[-3:]\n",
    "        if ( (ab2name[ATeam] == Team1Name and HTeam == Team2Abbrev) or\n",
    "             (ab2name[HTeam] == Team1Name and ATeam == Team2Abbrev) ):\n",
    "            # Found the correct game!\n",
    "            # Extract the gamecenter number\n",
    "            gc_num = entries[2].find('a').attrs[\"href\"].split('/')[-1]\n",
    "            # Build the gamecenter url\n",
    "            gc_url = nhl_gc_base_url.format(ATeam.lower(),HTeam.lower(),date.replace('-','/'),gc_num)\n",
    "            break\n",
    "    # Now scrape the gamecenter data and compare the forwards there and in the dataframe\n",
    "    try:\n",
    "        soup = BeautifulSoup(open(\"data/nhl_gamecenter{0}vs{1}on{2}.html\".format(ATeam,HTeam,date)), \"html.parser\")  \n",
    "    except FileNotFoundError:\n",
    "        print(gc_url)\n",
    "        driver.get(gc_url)\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        with open(\"data/nhl_gamecenter{0}vs{1}on{2}.html\".format(ATeam,HTeam,date), \"w\") as f:\n",
    "            f.write(str(soup))\n",
    "    lfixed = False\n",
    "    for loc in (\"A\",\"H\"):\n",
    "        if loc == \"A\":\n",
    "            roster = soup.find('div',{\"class\":\"away\"})\n",
    "        else:\n",
    "            roster = soup.find('div',{\"class\":\"home\"})\n",
    "        forwards = roster.find_all(\"table\",{\"data-position\":\"skaters\"})[1]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Make sure it is the forwards\n",
    "        thead = forwards.find(\"thead\")\n",
    "        assert thead.find_all('th')[1].find(\"span\").text == \"Forwards\"\n",
    "\n",
    "        # Get list\n",
    "        allf  = forwards.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "        ## Find which players are in here and in dataframe ##\n",
    "        # First make a dictionary to save which column (position) in the dataframe is also on nhl.com\n",
    "        df_on_nhl = {}\n",
    "        for line in range(1,5):\n",
    "            for pos in range(3):\n",
    "                df_on_nhl[\"{0}L{1}-{2}\".format(loc,line,pos)] = False\n",
    "        # Also make an empty list to find which (if any) forwards are on nhl.com but not in df\n",
    "        not_in_df = []\n",
    "        ls = True\n",
    "        for f in allf:\n",
    "            # Get name (from player url)\n",
    "            player_url = f.find_all(\"span\")[1].find(\"a\").attrs[\"href\"]\n",
    "            split_name = player_url.split(\"/\")[-1].split(\"-\")[0:-1]\n",
    "            nhl_name  = \" \".join(split_name).title()\n",
    "            # In dataframe?\n",
    "            lfound = False \n",
    "            for line in range(1,5):\n",
    "                for pos in range(3):\n",
    "                    # Check name\n",
    "                    df_name = df[\"{0}L{1}-{2}\".format(loc,line,pos)].iat[i]\n",
    "                    #print(df_name,nhl_name)\n",
    "                    if (check_name(nhl_name,df_name)):\n",
    "                        df_on_nhl[\"{0}L{1}-{2}\".format(loc,line,pos)] = True\n",
    "                        lfound = True\n",
    "                        break\n",
    "                if lfound: \n",
    "                    break\n",
    "            if not lfound:\n",
    "                not_in_df.append(nhl_name)\n",
    "        # After looping, see if there are any \n",
    "        for val in not_in_df:\n",
    "            print(val,\"not on dataframe ({0} Team)\".format(loc))\n",
    "        Num_only_nhl = 0\n",
    "        for df_loc, tf in df_on_nhl.items():\n",
    "            if not tf:\n",
    "                print(df_loc,\"not on nhl\")\n",
    "                print(df[df_loc].iat[i],\"not on nhl ({0} Team)\".format(loc))\n",
    "                # Save last column on dataframe where there is a mistake\n",
    "                # If there is only one, this player will be replaced\n",
    "                df_loc_sav = df_loc\n",
    "                Num_only_nhl += 1\n",
    "        # Make the replacement if there is only one missing player\n",
    "        if len(not_in_df) == 1:\n",
    "            print(\"Changing df['{0}'].iat[{1}] from {2} to {3} ({4} Team)\".format(\n",
    "                  df_loc_sav,i,df[df_loc_sav].iat[i],not_in_df[0],loc))\n",
    "            #df[df_loc_sav].iat[i] = not_in_df[0][0]+\" \"+not_in_df[0][1]\n",
    "            lfixed = True\n",
    "        elif len(not_in_df) == 0 and Num_only_nhl > 0:\n",
    "            # This means they dressed less forwards\n",
    "            for df_loc, tf in df_on_nhl.items():\n",
    "                if not tf:\n",
    "                    print(\"Changing df['{0}'].iat[{1}] from {2} to {3} ({4} Team)\".format(\n",
    "                  df_loc,i,df[df_loc].iat[i],\"None None\",loc))\n",
    "                    #df[df_loc].iat[i] = \"None None\"\n",
    "                    lfixed = True\n",
    "        print()\n",
    "    if lfixed:\n",
    "        num_fix += 1\n",
    "    num_check += 1\n",
    "    print(\"{0}/{1}\".format(num_fix,num_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in (\"A\",\"H\"):\n",
    "    for line in range(1,5):\n",
    "        for pos in range(3):\n",
    "            print(df[\"{0}L{1}-{2}\".format(loc,line,pos)].iat[61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lA = np.empty(len(df.columns),dtype='?')\n",
    "i = 0\n",
    "for c in df.columns:\n",
    "    lA[i] = (c[:2] == \"AL\")\n",
    "    i +=1\n",
    "print(lA)\n",
    "print(df.columns[np.where(lA)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in (\"A\",\"H\"):\n",
    "    for line in range(1,5):\n",
    "        for pos in range(3):\n",
    "            print(\"{0}L{1}-{2}\".format(loc,line,pos),df[\"{0}L{1}-{2}\".format(loc,line,pos)].iat[145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
